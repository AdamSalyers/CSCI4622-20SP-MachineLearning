{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In-class notebook : Decision tree visualization and hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will learn how to visualize a trained decision tree classifier. We will also manually tune the `hyperparameters` of the tree and visualize the results of that tuning. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will run this cell that improrts the required libraries for this exercise. We will be using a python package called pydotplus. Make sure you install this in your python distribution. You will also have to download the graphviz software [https://graphviz.gitlab.io/download/]. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "\n",
    "import pydotplus\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure that your graphviz executables are added to your PATH variable, please run the following cell. Replace the RHS of graphviz_path with your actual path to the Graphviz bin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "graphviz_path = 'C:/Program Files (x86)/Graphviz2.38/bin/'\n",
    "os.environ[\"PATH\"] += os.pathsep + graphviz_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/residency.csv')\n",
    "df = df.drop('Unnamed: 0',axis=1)\n",
    "y = df['Residency']\n",
    "X= df.drop('Residency',axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(clf, out_file=dot_data, filled=True, rounded=True, special_characters=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ### There is another way to make the tree graph, but the visualization process is similar (we use export_graphviz)\n",
    "from sklearn import tree\n",
    "tree.plot_tree(clf.fit(X, y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cat_features=preprocessor.transformers_[1][1]['onehot']\\\n",
    "                         .get_feature_names(categorical_features)\n",
    "# dot_data = tree.export_graphviz(clf, out_file=None,feature_names=list(numeric_features)+list(new_cat_features),class_names=['No','Yes'],filled=True, rounded=True,special_characters=True)\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,feature_names=['Age','Salary','Degree'],class_names=['No','Yes'],filled=True, rounded=True,special_characters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "graph = graphviz.Source(dot_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(graph.create_png())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/Heart_cleaned.csv\")\n",
    "df = df.drop('Unnamed: 0',axis=1)\n",
    "\n",
    "y= df['AHD']\n",
    "X = df.drop('AHD',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "clf.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#new_cat_features=preprocessor.transformers_[1][1]['onehot']\\\n",
    "                         #.get_feature_names(categorical_features)\n",
    "    \n",
    "new_cat_features = list(X.columns)\n",
    "dot_data = tree.export_graphviz(clf, out_file=None,feature_names=new_cat_features,class_names=['No','Yes'],filled=True, rounded=True,special_characters=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz\n",
    "graph = graphviz.Source(dot_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises: Manual and automatic hyperparameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Grow a decision tree classifier and change its options and visualize the tree to check what's happening\n",
    "- 1.1 `max_depth`\n",
    "- 1.2 `min_samples_split`\n",
    "- 1.3 `min_samples_leaf`\n",
    "- 1.4 `max_features`\n",
    "- 1.5 `min_impurity_decrease`    \n",
    "See the [document](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier.fit) for details.\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.get_params() #check the default options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, the max_depth is None by default. Seeing the visualization above, the depth grows over 10. \n",
    "# So we can pick a max_depth that's smaller than 10, for example let's pick 5.\n",
    "# Note that the example numbers here are for demo purpose and would not necessarily be the best choice.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pick a performance metric (for classification) and optimize those tuning parameters. Does a tree perform better when fully grown or early stopped using those parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Specify the parameter space (max_depth, min_sample_split, min_samples_leaf)\n",
    "param_space={\n",
    "'max_depth' : [3, 5, 7, 9, None],\n",
    "'min_samples_split' : [2, 3, 5],\n",
    "'min_samples_leaf' : [1, 2, 3, 5],\n",
    "'max_features' : [4, 8, None]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sklearn has a convenient function that can do grid search, as well as cross validation.\n",
    "# see more in https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "\n",
    "\n",
    "#If you want to use different types of cv (e.g. stratified- which also takes care of class label imbalance), you can construct cv object.\n",
    "# see more in https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.KFold.html#sklearn.model_selection.KFold\n",
    "# and https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
